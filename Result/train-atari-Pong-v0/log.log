[32m[0311 00:38:31 @logger.py:74][0m Argv: no-shared-double-train-atari.py --env Pong-v0 --gpu 0
[32m[0311 00:38:31 @no-shared-double-train-atari.py:247][0m [Batch-A3C] Train on gpu 0 and infer on gpu 0
[32m[0311 00:38:32 @param.py:195][0m Use train_log/train-atari-Pong-v0/hyper.txt to set hyperparam: 'learning_rate'.
[32m[0311 00:38:32 @param.py:195][0m Use train_log/train-atari-Pong-v0/hyper.txt to set hyperparam: 'entropy_beta'.
[32m[0311 00:38:32 @sesscreate.py:39][0m [5m[31mWRN[0m Some options in custom session config may not work due to TF bugs. See https://github.com/ppwwyyxx/tensorpack/issues/497 for workarounds.
[32m[0311 00:38:32 @registry.py:121][0m conv0 input: [None, 84, 84, 12]
[32m[0311 00:38:32 @registry.py:129][0m conv0 output: [None, 84, 84, 32]
[32m[0311 00:38:32 @registry.py:121][0m pool0 input: [None, 84, 84, 32]
[32m[0311 00:38:32 @registry.py:129][0m pool0 output: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:121][0m conv1-1 input: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:129][0m conv1-1 output: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:121][0m conv1-2 input: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:129][0m conv1-2 output: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:121][0m pool1-1 input: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:129][0m pool1-1 output: [None, 21, 21, 32]
[32m[0311 00:38:32 @registry.py:121][0m pool1-2 input: [None, 42, 42, 32]
[32m[0311 00:38:32 @registry.py:129][0m pool1-2 output: [None, 21, 21, 32]
[32m[0311 00:38:32 @registry.py:121][0m conv2-1 input: [None, 21, 21, 32]
[32m[0311 00:38:32 @registry.py:129][0m conv2-1 output: [None, 21, 21, 64]
[32m[0311 00:38:32 @registry.py:121][0m conv2-2 input: [None, 21, 21, 32]
[32m[0311 00:38:32 @registry.py:129][0m conv2-2 output: [None, 21, 21, 64]
[32m[0311 00:38:32 @registry.py:121][0m pool2-1 input: [None, 21, 21, 64]
[32m[0311 00:38:32 @registry.py:129][0m pool2-1 output: [None, 10, 10, 64]
[32m[0311 00:38:32 @registry.py:121][0m pool2-2 input: [None, 21, 21, 64]
[32m[0311 00:38:32 @registry.py:129][0m pool2-2 output: [None, 10, 10, 64]
[32m[0311 00:38:32 @registry.py:121][0m conv3-1 input: [None, 10, 10, 64]
[32m[0311 00:38:32 @registry.py:129][0m conv3-1 output: [None, 10, 10, 64]
[32m[0311 00:38:33 @registry.py:121][0m conv3-2 input: [None, 10, 10, 64]
[32m[0311 00:38:33 @registry.py:129][0m conv3-2 output: [None, 10, 10, 64]
[32m[0311 00:38:33 @registry.py:121][0m fc0-1 input: [None, 10, 10, 64]
[32m[0311 00:38:33 @registry.py:129][0m fc0-1 output: [None, 512]
[32m[0311 00:38:33 @registry.py:121][0m fc0-2 input: [None, 10, 10, 64]
[32m[0311 00:38:33 @registry.py:129][0m fc0-2 output: [None, 512]
[32m[0311 00:38:33 @registry.py:121][0m fc-pi input: [None, 1024]
[32m[0311 00:38:33 @registry.py:129][0m fc-pi output: [None, 6]
[32m[0311 00:38:33 @registry.py:121][0m fc-v_1 input: [None, 512]
[32m[0311 00:38:33 @registry.py:129][0m fc-v_1 output: [None, 1]
[32m[0311 00:38:33 @registry.py:121][0m fc-v_2 input: [None, 512]
[32m[0311 00:38:33 @registry.py:129][0m fc-v_2 output: [None, 1]
[32m[0311 00:38:34 @model_utils.py:49][0m [36mTrainable Variables: 
[0mname             shape               dim
---------------  --------------  -------
conv0/W:0        [5, 5, 12, 32]     9600
conv0/b:0        [32]                 32
conv1-1/W:0      [5, 5, 32, 32]    25600
conv1-1/b:0      [32]                 32
conv1-2/W:0      [5, 5, 32, 32]    25600
conv1-2/b:0      [32]                 32
conv2-1/W:0      [4, 4, 32, 64]    32768
conv2-1/b:0      [64]                 64
conv2-2/W:0      [4, 4, 32, 64]    32768
conv2-2/b:0      [64]                 64
conv3-1/W:0      [3, 3, 64, 64]    36864
conv3-1/b:0      [64]                 64
conv3-2/W:0      [3, 3, 64, 64]    36864
conv3-2/b:0      [64]                 64
fc0-1/W:0        [6400, 512]     3276800
fc0-1/b:0        [512]               512
prelu-1/alpha:0  []                    1
fc0-2/W:0        [6400, 512]     3276800
fc0-2/b:0        [512]               512
prelu-2/alpha:0  []                    1
fc-pi/W:0        [1024, 6]          6144
fc-pi/b:0        [6]                   6
fc-v_1/W:0       [512, 1]            512
fc-v_1/b:0       [1]                   1
fc-v_2/W:0       [512, 1]            512
fc-v_2/b:0       [1]                   1[36m
Total #vars=26, #params=6762218, size=25.80MB[0m
[32m[0311 00:38:34 @base.py:204][0m Setup callbacks graph ...
[32m[0311 00:38:35 @predict.py:42][0m Building predictor tower 'tower-pred-0' on device /gpu:0 ...
[32m[0311 00:38:35 @summary.py:34][0m Maintain moving average summary of 37 tensors.
[32m[0311 00:38:35 @summary.py:71][0m Summarizing collection 'summaries' of size 63
[32m[0311 00:38:35 @base.py:220][0m Creating the session ...
[32m[0311 00:39:06 @base.py:228][0m Initializing the session ...
[32m[0311 00:39:06 @base.py:235][0m Graph Finalized.
[32m[0311 00:39:06 @concurrency.py:38][0m Starting SimulatorMaster ...
[32m[0311 00:39:06 @base.py:255][0m Start Epoch 1 ...
[32m[0311 00:58:28 @base.py:265][0m Epoch 1 (global_step 6000) finished, time:19 minutes 21 seconds.
[32m[0311 00:58:28 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-6000.
[32m[0311 01:00:07 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.0015722
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0042161
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00024438
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.005427
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00020629
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0043278
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00016914
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0040904
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.0001522
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.003411
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00022305
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0061221
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.0001773
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0063112
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00044819
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0049909
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0023402
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.026814
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0020712
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.027404
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.4422e-05
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0010449
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.202e-05
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.0012484
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0054499
[32m[0311 01:00:07 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014082
[32m[0311 01:00:07 @monitor.py:393][0m cost: -0.010107
[32m[0311 01:00:07 @monitor.py:393][0m importance: 0.99996
[32m[0311 01:00:07 @monitor.py:393][0m max_score: -18
[32m[0311 01:00:07 @monitor.py:393][0m mean_score: -20.7
[32m[0311 01:00:07 @monitor.py:393][0m policy_loss: -0.709
[32m[0311 01:00:07 @monitor.py:393][0m predict_reward_1: -1.4945
[32m[0311 01:00:07 @monitor.py:393][0m predict_reward_2: -1.5071
[32m[0311 01:00:07 @monitor.py:393][0m predict_reward_avg: -1.5008
[32m[0311 01:00:07 @monitor.py:393][0m rms_advantage_1: 0.15807
[32m[0311 01:00:07 @monitor.py:393][0m rms_advantage_2: 0.15585
[32m[0311 01:00:07 @monitor.py:393][0m rms_advantage_avg: 0.15696
[32m[0311 01:00:07 @monitor.py:393][0m value_loss: 1.7012
[32m[0311 01:00:07 @monitor.py:393][0m xentropy_loss: -228.59
[32m[0311 01:00:07 @group.py:44][0m Callbacks took 99.374 sec in total. PeriodicTrigger-Evaluator: 1 minute 39 seconds
[32m[0311 01:00:07 @base.py:255][0m Start Epoch 2 ...
[32m[0311 01:19:09 @base.py:265][0m Epoch 2 (global_step 12000) finished, time:19 minutes 1 second.
[32m[0311 01:19:09 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-12000.
[32m[0311 01:20:43 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00061517
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0014261
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00012226
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00222
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014091
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0022969
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00010188
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0017768
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00011857
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0022939
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010154
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0034197
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00011682
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0040164
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00032968
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0042499
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0011562
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.014024
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012045
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.016902
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.4469e-05
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00072559
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 1.5316e-05
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00092259
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0032802
[32m[0311 01:20:43 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.0089826
[32m[0311 01:20:43 @monitor.py:393][0m cost: -0.009645
[32m[0311 01:20:43 @monitor.py:393][0m importance: 1
[32m[0311 01:20:43 @monitor.py:393][0m max_score: -21
[32m[0311 01:20:43 @monitor.py:393][0m mean_score: -21
[32m[0311 01:20:43 @monitor.py:393][0m policy_loss: -0.042918
[32m[0311 01:20:43 @monitor.py:393][0m predict_reward_1: -1.6029
[32m[0311 01:20:43 @monitor.py:393][0m predict_reward_2: -1.6054
[32m[0311 01:20:43 @monitor.py:393][0m predict_reward_avg: -1.6042
[32m[0311 01:20:43 @monitor.py:393][0m rms_advantage_1: 0.12374
[32m[0311 01:20:43 @monitor.py:393][0m rms_advantage_2: 0.12893
[32m[0311 01:20:43 @monitor.py:393][0m rms_advantage_avg: 0.12633
[32m[0311 01:20:43 @monitor.py:393][0m value_loss: 1.0716
[32m[0311 01:20:43 @monitor.py:393][0m xentropy_loss: -226.33
[32m[0311 01:20:43 @group.py:44][0m Callbacks took 93.978 sec in total. PeriodicTrigger-Evaluator: 1 minute 33 seconds
[32m[0311 01:20:43 @base.py:255][0m Start Epoch 3 ...
[32m[0311 01:39:45 @base.py:265][0m Epoch 3 (global_step 18000) finished, time:19 minutes 1 second.
[32m[0311 01:39:45 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-18000.
[32m[0311 01:44:12 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00089582
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.002059
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00016553
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0024769
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00021785
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0030055
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014386
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0019207
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00018987
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0022429
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.0001352
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0024347
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00017732
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0025244
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00032203
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0048105
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00084088
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.011727
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010676
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.016606
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0808e-05
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00083269
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.5422e-05
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00094243
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0066948
[32m[0311 01:44:12 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.012023
[32m[0311 01:44:12 @monitor.py:393][0m cost: -0.0084206
[32m[0311 01:44:12 @monitor.py:393][0m importance: 1.0001
[32m[0311 01:44:12 @monitor.py:393][0m max_score: -12
[32m[0311 01:44:12 @monitor.py:393][0m mean_score: -16.26
[32m[0311 01:44:12 @monitor.py:393][0m policy_loss: -0.49547
[32m[0311 01:44:12 @monitor.py:393][0m predict_reward_1: -0.71488
[32m[0311 01:44:12 @monitor.py:393][0m predict_reward_2: -0.71646
[32m[0311 01:44:12 @monitor.py:393][0m predict_reward_avg: -0.71567
[32m[0311 01:44:12 @monitor.py:393][0m rms_advantage_1: 0.15281
[32m[0311 01:44:12 @monitor.py:393][0m rms_advantage_2: 0.15926
[32m[0311 01:44:12 @monitor.py:393][0m rms_advantage_avg: 0.15604
[32m[0311 01:44:12 @monitor.py:393][0m value_loss: 1.6172
[32m[0311 01:44:12 @monitor.py:393][0m xentropy_loss: -219.96
[32m[0311 01:44:12 @group.py:44][0m Callbacks took 267.067 sec in total. PeriodicTrigger-Evaluator: 4 minutes 26 seconds
[32m[0311 01:44:12 @base.py:255][0m Start Epoch 4 ...
[32m[0311 02:03:16 @base.py:265][0m Epoch 4 (global_step 24000) finished, time:19 minutes 4 seconds.
[32m[0311 02:03:16 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-24000.
[32m[0311 02:10:13 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00092772
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0020277
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00016267
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0019861
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00027349
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0029494
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014243
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0015821
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00023607
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0019981
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012599
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0019736
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00019807
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0020049
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030181
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.004
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.001041
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.018617
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0014896
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.022025
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.176e-05
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00074331
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.9198e-05
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.0007438
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.013284
[32m[0311 02:10:13 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.027493
[32m[0311 02:10:13 @monitor.py:393][0m cost: -0.013089
[32m[0311 02:10:13 @monitor.py:393][0m importance: 0.99843
[32m[0311 02:10:13 @monitor.py:393][0m max_score: 7
[32m[0311 02:10:13 @monitor.py:393][0m mean_score: -7.6
[32m[0311 02:10:13 @monitor.py:393][0m policy_loss: -0.85401
[32m[0311 02:10:13 @monitor.py:393][0m predict_reward_1: -0.31534
[32m[0311 02:10:13 @monitor.py:393][0m predict_reward_2: -0.31305
[32m[0311 02:10:13 @monitor.py:393][0m predict_reward_avg: -0.31419
[32m[0311 02:10:13 @monitor.py:393][0m rms_advantage_1: 0.13839
[32m[0311 02:10:13 @monitor.py:393][0m rms_advantage_2: 0.13535
[32m[0311 02:10:13 @monitor.py:393][0m rms_advantage_avg: 0.13687
[32m[0311 02:10:13 @monitor.py:393][0m value_loss: 1.2524
[32m[0311 02:10:13 @monitor.py:393][0m xentropy_loss: -207.37
[32m[0311 02:10:13 @group.py:44][0m Callbacks took 416.965 sec in total. PeriodicTrigger-Evaluator: 6 minutes 56 seconds
[32m[0311 02:10:13 @base.py:255][0m Start Epoch 5 ...
[32m[0311 02:29:15 @base.py:265][0m Epoch 5 (global_step 30000) finished, time:19 minutes 2 seconds.
[32m[0311 02:29:16 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-30000.
[32m[0311 02:42:11 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00066751
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0013703
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00015557
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0016039
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00021434
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0020486
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014211
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0012713
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00019433
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0014095
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012933
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0014084
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.0001741
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0014104
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00029168
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0037122
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00072696
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.010266
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.001023
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.013759
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.2584e-05
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00063582
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7069e-05
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00058833
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0069214
[32m[0311 02:42:11 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014483
[32m[0311 02:42:11 @monitor.py:393][0m cost: -0.0049035
[32m[0311 02:42:11 @monitor.py:393][0m importance: 0.99986
[32m[0311 02:42:11 @monitor.py:393][0m max_score: 9
[32m[0311 02:42:11 @monitor.py:393][0m mean_score: -0.96
[32m[0311 02:42:11 @monitor.py:393][0m policy_loss: 0.2072
[32m[0311 02:42:11 @monitor.py:393][0m predict_reward_1: -0.16166
[32m[0311 02:42:11 @monitor.py:393][0m predict_reward_2: -0.15923
[32m[0311 02:42:11 @monitor.py:393][0m predict_reward_avg: -0.16045
[32m[0311 02:42:11 @monitor.py:393][0m rms_advantage_1: 0.13155
[32m[0311 02:42:11 @monitor.py:393][0m rms_advantage_2: 0.13952
[32m[0311 02:42:11 @monitor.py:393][0m rms_advantage_avg: 0.13554
[32m[0311 02:42:12 @monitor.py:393][0m value_loss: 1.286
[32m[0311 02:42:12 @monitor.py:393][0m xentropy_loss: -212.08
[32m[0311 02:42:12 @group.py:44][0m Callbacks took 776.212 sec in total. PeriodicTrigger-Evaluator: 12 minutes 55 seconds
[32m[0311 02:42:12 @base.py:255][0m Start Epoch 6 ...
[32m[0311 03:01:13 @base.py:265][0m Epoch 6 (global_step 36000) finished, time:19 minutes 1 second.
[32m[0311 03:01:13 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-36000.
[32m[0311 03:11:13 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.0009575
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0021827
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00020112
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0016001
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00034866
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0026242
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00016166
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0013523
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00027757
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0016645
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.0001399
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0014741
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00020926
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0016882
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00032284
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.00411
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00070978
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.012542
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012755
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.014645
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1343e-05
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00064927
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7902e-05
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00060947
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0080407
[32m[0311 03:11:13 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.017673
[32m[0311 03:11:13 @monitor.py:393][0m cost: -0.0090122
[32m[0311 03:11:13 @monitor.py:393][0m importance: 1.001
[32m[0311 03:11:13 @monitor.py:393][0m max_score: 8
[32m[0311 03:11:13 @monitor.py:393][0m mean_score: -3.1277
[32m[0311 03:11:13 @monitor.py:393][0m policy_loss: -0.264
[32m[0311 03:11:13 @monitor.py:393][0m predict_reward_1: -0.15564
[32m[0311 03:11:13 @monitor.py:393][0m predict_reward_2: -0.15257
[32m[0311 03:11:13 @monitor.py:393][0m predict_reward_avg: -0.1541
[32m[0311 03:11:13 @monitor.py:393][0m rms_advantage_1: 0.13162
[32m[0311 03:11:13 @monitor.py:393][0m rms_advantage_2: 0.13219
[32m[0311 03:11:13 @monitor.py:393][0m rms_advantage_avg: 0.1319
[32m[0311 03:11:13 @monitor.py:393][0m value_loss: 1.2109
[32m[0311 03:11:13 @monitor.py:393][0m xentropy_loss: -210.04
[32m[0311 03:11:13 @group.py:44][0m Callbacks took 600.746 sec in total. PeriodicTrigger-Evaluator: 10 minutes
[32m[0311 03:11:13 @base.py:255][0m Start Epoch 7 ...
[32m[0311 03:30:15 @base.py:265][0m Epoch 7 (global_step 42000) finished, time:19 minutes 1 second.
[32m[0311 03:30:16 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-42000.
[32m[0311 03:41:36 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.0006462
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.001409
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011463
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0011971
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00019312
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0019864
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.0001266
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0010898
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00018173
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0013004
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011167
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0012469
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00016032
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0011936
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00028758
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0032474
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00063894
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0093236
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0011044
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0083852
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.8653e-05
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00053314
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.6182e-05
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00042265
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.008586
[32m[0311 03:41:36 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.01034
[32m[0311 03:41:36 @monitor.py:393][0m cost: -0.013414
[32m[0311 03:41:36 @monitor.py:393][0m importance: 1.0003
[32m[0311 03:41:36 @monitor.py:393][0m max_score: 10
[32m[0311 03:41:36 @monitor.py:393][0m mean_score: -1.5682
[32m[0311 03:41:36 @monitor.py:393][0m policy_loss: -0.7367
[32m[0311 03:41:36 @monitor.py:393][0m predict_reward_1: -0.10821
[32m[0311 03:41:36 @monitor.py:393][0m predict_reward_2: -0.10675
[32m[0311 03:41:36 @monitor.py:393][0m predict_reward_avg: -0.10748
[32m[0311 03:41:36 @monitor.py:393][0m rms_advantage_1: 0.12121
[32m[0311 03:41:36 @monitor.py:393][0m rms_advantage_2: 0.12416
[32m[0311 03:41:36 @monitor.py:393][0m rms_advantage_avg: 0.12269
[32m[0311 03:41:36 @monitor.py:393][0m value_loss: 1.0782
[32m[0311 03:41:36 @monitor.py:393][0m xentropy_loss: -205.85
[32m[0311 03:41:36 @group.py:44][0m Callbacks took 680.944 sec in total. PeriodicTrigger-Evaluator: 11 minutes 20 seconds
[32m[0311 03:41:36 @base.py:255][0m Start Epoch 8 ...
[32m[0311 04:00:37 @base.py:265][0m Epoch 8 (global_step 48000) finished, time:19 minutes.
[32m[0311 04:00:37 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-48000.
[32m[0311 04:08:34 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00071379
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0015147
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00013164
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0013139
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00019415
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0018689
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014178
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0010302
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00018215
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0012509
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012614
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0011843
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00015894
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0011307
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00032018
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0037083
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00084845
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.013852
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0014655
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.010519
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1727e-05
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0005258
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7544e-05
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00042741
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0094325
[32m[0311 04:08:34 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.015732
[32m[0311 04:08:34 @monitor.py:393][0m cost: -0.0085824
[32m[0311 04:08:34 @monitor.py:393][0m importance: 1.0005
[32m[0311 04:08:34 @monitor.py:393][0m max_score: 9
[32m[0311 04:08:34 @monitor.py:393][0m mean_score: -0.5122
[32m[0311 04:08:34 @monitor.py:393][0m policy_loss: -0.15744
[32m[0311 04:08:34 @monitor.py:393][0m predict_reward_1: -0.05987
[32m[0311 04:08:34 @monitor.py:393][0m predict_reward_2: -0.061321
[32m[0311 04:08:34 @monitor.py:393][0m predict_reward_avg: -0.060595
[32m[0311 04:08:34 @monitor.py:393][0m rms_advantage_1: 0.12528
[32m[0311 04:08:34 @monitor.py:393][0m rms_advantage_2: 0.1262
[32m[0311 04:08:34 @monitor.py:393][0m rms_advantage_avg: 0.12574
[32m[0311 04:08:34 @monitor.py:393][0m value_loss: 1.1205
[32m[0311 04:08:34 @monitor.py:393][0m xentropy_loss: -206.16
[32m[0311 04:08:34 @group.py:44][0m Callbacks took 477.387 sec in total. PeriodicTrigger-Evaluator: 7 minutes 57 seconds
[32m[0311 04:08:34 @base.py:255][0m Start Epoch 9 ...
[32m[0311 04:27:35 @base.py:265][0m Epoch 9 (global_step 54000) finished, time:19 minutes.
[32m[0311 04:27:35 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-54000.
[32m[0311 04:37:34 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00073156
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0016605
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00012578
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0010074
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00022029
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0017164
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00011194
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00082112
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00017946
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0011168
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.5756e-05
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00096211
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00015944
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0010627
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00027178
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.003134
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00066035
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.010393
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012194
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.010172
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.6287e-05
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00043305
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.4714e-05
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00038767
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0064704
[32m[0311 04:37:34 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.011066
[32m[0311 04:37:34 @monitor.py:393][0m cost: -0.0055503
[32m[0311 04:37:34 @monitor.py:393][0m importance: 1.0002
[32m[0311 04:37:34 @monitor.py:393][0m max_score: 10
[32m[0311 04:37:34 @monitor.py:393][0m mean_score: 0.02439
[32m[0311 04:37:34 @monitor.py:393][0m policy_loss: 0.40164
[32m[0311 04:37:34 @monitor.py:393][0m predict_reward_1: -0.11056
[32m[0311 04:37:34 @monitor.py:393][0m predict_reward_2: -0.10647
[32m[0311 04:37:34 @monitor.py:393][0m predict_reward_avg: -0.10852
[32m[0311 04:37:34 @monitor.py:393][0m rms_advantage_1: 0.11805
[32m[0311 04:37:34 @monitor.py:393][0m rms_advantage_2: 0.11688
[32m[0311 04:37:34 @monitor.py:393][0m rms_advantage_avg: 0.11746
[32m[0311 04:37:34 @monitor.py:393][0m value_loss: 0.95144
[32m[0311 04:37:34 @monitor.py:393][0m xentropy_loss: -206.35
[32m[0311 04:37:34 @group.py:44][0m Callbacks took 599.801 sec in total. PeriodicTrigger-Evaluator: 9 minutes 59 seconds
[32m[0311 04:37:34 @base.py:255][0m Start Epoch 10 ...
[32m[0311 04:56:34 @base.py:265][0m Epoch 10 (global_step 60000) finished, time:18 minutes 59 seconds.
[32m[0311 04:56:34 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-60000.
[32m[0311 05:08:10 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00093098
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0021565
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00016051
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0013406
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00027776
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0023112
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00015744
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0010494
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00025831
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0016044
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00013887
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0011181
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00022501
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0014008
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00036006
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.003924
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00084083
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.011257
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013202
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.011503
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.2988e-05
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00049898
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 3.2727e-05
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00046582
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0077738
[32m[0311 05:08:10 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014758
[32m[0311 05:08:10 @monitor.py:393][0m cost: -0.011172
[32m[0311 05:08:10 @monitor.py:393][0m importance: 0.99972
[32m[0311 05:08:10 @monitor.py:393][0m max_score: 15
[32m[0311 05:08:10 @monitor.py:393][0m mean_score: 2.9268
[32m[0311 05:08:10 @monitor.py:393][0m policy_loss: -0.61884
[32m[0311 05:08:10 @monitor.py:393][0m predict_reward_1: -0.060012
[32m[0311 05:08:10 @monitor.py:393][0m predict_reward_2: -0.056552
[32m[0311 05:08:10 @monitor.py:393][0m predict_reward_avg: -0.058282
[32m[0311 05:08:10 @monitor.py:393][0m rms_advantage_1: 0.13046
[32m[0311 05:08:10 @monitor.py:393][0m rms_advantage_2: 0.1318
[32m[0311 05:08:10 @monitor.py:393][0m rms_advantage_avg: 0.13113
[32m[0311 05:08:10 @monitor.py:393][0m value_loss: 1.2922
[32m[0311 05:08:10 @monitor.py:393][0m xentropy_loss: -210.33
[32m[0311 05:08:10 @group.py:44][0m Callbacks took 695.772 sec in total. PeriodicTrigger-Evaluator: 11 minutes 35 seconds
[32m[0311 05:08:10 @base.py:255][0m Start Epoch 11 ...
[32m[0311 05:27:11 @base.py:265][0m Epoch 11 (global_step 66000) finished, time:19 minutes.
[32m[0311 05:27:11 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-66000.
[32m[0311 05:36:59 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00068817
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0014534
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00013106
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0010263
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00021445
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0016933
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013634
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00087445
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00019796
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0011359
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012586
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0010483
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00018176
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00122
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00033968
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0037059
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00076755
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.012162
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0011956
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0093907
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.2908e-05
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00048693
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.9867e-05
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.0004307
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0095341
[32m[0311 05:36:59 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014035
[32m[0311 05:36:59 @monitor.py:393][0m cost: -0.0033366
[32m[0311 05:36:59 @monitor.py:393][0m importance: 1.0001
[32m[0311 05:36:59 @monitor.py:393][0m max_score: 12
[32m[0311 05:36:59 @monitor.py:393][0m mean_score: 4.1842
[32m[0311 05:36:59 @monitor.py:393][0m policy_loss: 0.53086
[32m[0311 05:36:59 @monitor.py:393][0m predict_reward_1: 0.038456
[32m[0311 05:36:59 @monitor.py:393][0m predict_reward_2: 0.039432
[32m[0311 05:36:59 @monitor.py:393][0m predict_reward_avg: 0.038944
[32m[0311 05:36:59 @monitor.py:393][0m rms_advantage_1: 0.1255
[32m[0311 05:36:59 @monitor.py:393][0m rms_advantage_2: 0.12762
[32m[0311 05:36:59 @monitor.py:393][0m rms_advantage_avg: 0.12656
[32m[0311 05:36:59 @monitor.py:393][0m value_loss: 1.1472
[32m[0311 05:36:59 @monitor.py:393][0m xentropy_loss: -210.51
[32m[0311 05:36:59 @group.py:44][0m Callbacks took 587.963 sec in total. PeriodicTrigger-Evaluator: 9 minutes 47 seconds
[32m[0311 05:36:59 @base.py:255][0m Start Epoch 12 ...
[32m[0311 05:55:58 @base.py:265][0m Epoch 12 (global_step 72000) finished, time:18 minutes 59 seconds.
[32m[0311 05:55:58 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-72000.
[32m[0311 06:04:26 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00065352
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0013612
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00014155
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0011809
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00019229
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0014476
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00015121
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00092335
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00018626
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0010472
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012628
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0010266
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00016156
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00097161
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.000317
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0030726
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.001006
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.010322
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.001043
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0077444
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1937e-05
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00041682
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.5384e-05
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00034792
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0071711
[32m[0311 06:04:27 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.010554
[32m[0311 06:04:27 @monitor.py:393][0m cost: -0.012127
[32m[0311 06:04:27 @monitor.py:393][0m importance: 0.99992
[32m[0311 06:04:27 @monitor.py:393][0m max_score: 16
[32m[0311 06:04:27 @monitor.py:393][0m mean_score: 5.9474
[32m[0311 06:04:27 @monitor.py:393][0m policy_loss: -0.46061
[32m[0311 06:04:27 @monitor.py:393][0m predict_reward_1: -0.04614
[32m[0311 06:04:27 @monitor.py:393][0m predict_reward_2: -0.045875
[32m[0311 06:04:27 @monitor.py:393][0m predict_reward_avg: -0.046007
[32m[0311 06:04:27 @monitor.py:393][0m rms_advantage_1: 0.11568
[32m[0311 06:04:27 @monitor.py:393][0m rms_advantage_2: 0.11175
[32m[0311 06:04:27 @monitor.py:393][0m rms_advantage_avg: 0.11371
[32m[0311 06:04:27 @monitor.py:393][0m value_loss: 0.9635
[32m[0311 06:04:27 @monitor.py:393][0m xentropy_loss: -205.51
[32m[0311 06:04:27 @group.py:44][0m Callbacks took 508.910 sec in total. PeriodicTrigger-Evaluator: 8 minutes 28 seconds
[32m[0311 06:04:27 @base.py:255][0m Start Epoch 13 ...
[32m[0311 06:23:26 @base.py:265][0m Epoch 13 (global_step 78000) finished, time:18 minutes 59 seconds.
[32m[0311 06:23:26 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-78000.
[32m[0311 06:34:23 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00064793
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0012524
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00014195
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00084235
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00023505
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0013555
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.0001098
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00067878
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016238
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00089386
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 8.8465e-05
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00082446
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00012404
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0010949
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00024721
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027189
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00051707
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0084923
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010089
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0095671
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.5804e-05
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00036537
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.1029e-05
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00033125
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.005731
[32m[0311 06:34:23 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014848
[32m[0311 06:34:23 @monitor.py:393][0m cost: -0.01424
[32m[0311 06:34:23 @monitor.py:393][0m importance: 1.0003
[32m[0311 06:34:23 @monitor.py:393][0m max_score: 13
[32m[0311 06:34:23 @monitor.py:393][0m mean_score: 2.1316
[32m[0311 06:34:23 @monitor.py:393][0m policy_loss: -0.48049
[32m[0311 06:34:23 @monitor.py:393][0m predict_reward_1: -0.03727
[32m[0311 06:34:23 @monitor.py:393][0m predict_reward_2: -0.040943
[32m[0311 06:34:23 @monitor.py:393][0m predict_reward_avg: -0.039107
[32m[0311 06:34:23 @monitor.py:393][0m rms_advantage_1: 0.10049
[32m[0311 06:34:23 @monitor.py:393][0m rms_advantage_2: 0.10608
[32m[0311 06:34:23 @monitor.py:393][0m rms_advantage_avg: 0.10329
[32m[0311 06:34:23 @monitor.py:393][0m value_loss: 0.77613
[32m[0311 06:34:23 @monitor.py:393][0m xentropy_loss: -211.84
[32m[0311 06:34:23 @group.py:44][0m Callbacks took 656.723 sec in total. PeriodicTrigger-Evaluator: 10 minutes 56 seconds
[32m[0311 06:34:23 @base.py:255][0m Start Epoch 14 ...
[32m[0311 06:53:24 @base.py:265][0m Epoch 14 (global_step 84000) finished, time:19 minutes.
[32m[0311 06:53:24 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-84000.
[32m[0311 07:02:12 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00050104
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0010277
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011699
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00098621
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00017102
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0012864
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012192
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00074555
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016123
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00086365
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010875
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00077926
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00014853
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00095776
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00028932
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0031149
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00066774
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0095218
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0009904
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0083503
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.893e-05
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00037861
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.3831e-05
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00033695
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0072521
[32m[0311 07:02:12 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014097
[32m[0311 07:02:12 @monitor.py:393][0m cost: -0.01125
[32m[0311 07:02:12 @monitor.py:393][0m importance: 0.99998
[32m[0311 07:02:12 @monitor.py:393][0m max_score: 11
[32m[0311 07:02:12 @monitor.py:393][0m mean_score: 0.28571
[32m[0311 07:02:12 @monitor.py:393][0m policy_loss: -0.17473
[32m[0311 07:02:12 @monitor.py:393][0m predict_reward_1: -0.039097
[32m[0311 07:02:12 @monitor.py:393][0m predict_reward_2: -0.040725
[32m[0311 07:02:12 @monitor.py:393][0m predict_reward_avg: -0.039911
[32m[0311 07:02:12 @monitor.py:393][0m rms_advantage_1: 0.10637
[32m[0311 07:02:12 @monitor.py:393][0m rms_advantage_2: 0.1059
[32m[0311 07:02:12 @monitor.py:393][0m rms_advantage_avg: 0.10614
[32m[0311 07:02:12 @monitor.py:393][0m value_loss: 0.83414
[32m[0311 07:02:12 @monitor.py:393][0m xentropy_loss: -209.95
[32m[0311 07:02:12 @group.py:44][0m Callbacks took 528.326 sec in total. PeriodicTrigger-Evaluator: 8 minutes 48 seconds
[32m[0311 07:02:12 @base.py:255][0m Start Epoch 15 ...
[32m[0311 07:21:14 @base.py:265][0m Epoch 15 (global_step 90000) finished, time:19 minutes 1 second.
[32m[0311 07:21:14 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-90000.
[32m[0311 07:29:53 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00067163
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0012455
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.0001665
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00090282
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00025691
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0013753
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013252
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00080529
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00019373
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0012426
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011731
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00093077
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00017771
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0011648
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00034869
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0036252
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00082374
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.010277
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013968
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.010664
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.9739e-05
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0004101
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7406e-05
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00038301
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0090059
[32m[0311 07:29:53 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.015391
[32m[0311 07:29:53 @monitor.py:393][0m cost: -0.010876
[32m[0311 07:29:53 @monitor.py:393][0m importance: 0.99997
[32m[0311 07:29:53 @monitor.py:393][0m max_score: 15
[32m[0311 07:29:53 @monitor.py:393][0m mean_score: 6.7714
[32m[0311 07:29:53 @monitor.py:393][0m policy_loss: -0.28804
[32m[0311 07:29:53 @monitor.py:393][0m predict_reward_1: -0.0053639
[32m[0311 07:29:53 @monitor.py:393][0m predict_reward_2: -0.0030623
[32m[0311 07:29:53 @monitor.py:393][0m predict_reward_avg: -0.0042131
[32m[0311 07:29:53 @monitor.py:393][0m rms_advantage_1: 0.12084
[32m[0311 07:29:53 @monitor.py:393][0m rms_advantage_2: 0.12077
[32m[0311 07:29:53 @monitor.py:393][0m rms_advantage_avg: 0.12081
[32m[0311 07:29:53 @monitor.py:393][0m value_loss: 0.97472
[32m[0311 07:29:53 @monitor.py:393][0m xentropy_loss: -207.88
[32m[0311 07:29:53 @group.py:44][0m Callbacks took 519.400 sec in total. PeriodicTrigger-Evaluator: 8 minutes 39 seconds
[32m[0311 07:29:53 @base.py:255][0m Start Epoch 16 ...
[32m[0311 07:48:55 @base.py:265][0m Epoch 16 (global_step 96000) finished, time:19 minutes 2 seconds.
[32m[0311 07:48:56 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-96000.
[32m[0311 07:57:32 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00034675
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00069992
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 9.7001e-05
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00073334
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00010994
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00078951
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00010246
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00059611
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00011182
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00066298
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.6337e-05
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00075353
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00011
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0006491
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00024134
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027972
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00063607
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0070241
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.00081613
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0069037
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.7996e-05
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033713
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.1868e-05
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00028454
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0090622
[32m[0311 07:57:32 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.018186
[32m[0311 07:57:32 @monitor.py:393][0m cost: -0.0086105
[32m[0311 07:57:32 @monitor.py:393][0m importance: 1.0002
[32m[0311 07:57:32 @monitor.py:393][0m max_score: 17
[32m[0311 07:57:32 @monitor.py:393][0m mean_score: 11.229
[32m[0311 07:57:32 @monitor.py:393][0m policy_loss: 0.30995
[32m[0311 07:57:32 @monitor.py:393][0m predict_reward_1: 0.015807
[32m[0311 07:57:32 @monitor.py:393][0m predict_reward_2: 0.016395
[32m[0311 07:57:32 @monitor.py:393][0m predict_reward_avg: 0.016101
[32m[0311 07:57:32 @monitor.py:393][0m rms_advantage_1: 0.096634
[32m[0311 07:57:32 @monitor.py:393][0m rms_advantage_2: 0.10129
[32m[0311 07:57:32 @monitor.py:393][0m rms_advantage_avg: 0.098961
[32m[0311 07:57:32 @monitor.py:393][0m value_loss: 0.67258
[32m[0311 07:57:32 @monitor.py:393][0m xentropy_loss: -208.47
[32m[0311 07:57:32 @group.py:44][0m Callbacks took 516.447 sec in total. PeriodicTrigger-Evaluator: 8 minutes 36 seconds
[32m[0311 07:57:32 @base.py:255][0m Start Epoch 17 ...
[32m[0311 08:16:33 @base.py:265][0m Epoch 17 (global_step 102000) finished, time:19 minutes 1 second.
[32m[0311 08:16:33 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-102000.
[32m[0311 08:26:54 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00047208
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00087895
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00014229
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00089253
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00018679
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0011045
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013066
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00070834
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016659
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00096046
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011534
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00079916
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00016078
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00084644
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00026931
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0030144
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00068803
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0075308
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010598
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0085729
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.8139e-05
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033225
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.4391e-05
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00031515
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0093091
[32m[0311 08:26:54 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.016549
[32m[0311 08:26:54 @monitor.py:393][0m cost: -0.013824
[32m[0311 08:26:54 @monitor.py:393][0m importance: 1.0001
[32m[0311 08:26:54 @monitor.py:393][0m max_score: 13
[32m[0311 08:26:54 @monitor.py:393][0m mean_score: 5.4571
[32m[0311 08:26:54 @monitor.py:393][0m policy_loss: -0.35586
[32m[0311 08:26:54 @monitor.py:393][0m predict_reward_1: -0.042817
[32m[0311 08:26:54 @monitor.py:393][0m predict_reward_2: -0.039853
[32m[0311 08:26:54 @monitor.py:393][0m predict_reward_avg: -0.041335
[32m[0311 08:26:54 @monitor.py:393][0m rms_advantage_1: 0.09527
[32m[0311 08:26:54 @monitor.py:393][0m rms_advantage_2: 0.098623
[32m[0311 08:26:54 @monitor.py:393][0m rms_advantage_avg: 0.096946
[32m[0311 08:26:54 @monitor.py:393][0m value_loss: 0.7047
[32m[0311 08:26:54 @monitor.py:393][0m xentropy_loss: -211.84
[32m[0311 08:26:54 @group.py:44][0m Callbacks took 620.810 sec in total. PeriodicTrigger-Evaluator: 10 minutes 20 seconds
[32m[0311 08:26:54 @base.py:255][0m Start Epoch 18 ...
[32m[0311 08:45:55 @base.py:265][0m Epoch 18 (global_step 108000) finished, time:19 minutes 1 second.
[32m[0311 08:45:55 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-108000.
[32m[0311 08:53:38 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00046532
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00098836
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00010302
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00075631
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00015088
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010457
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00010703
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00059342
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00015661
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00080214
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.0073e-05
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00068425
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013907
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0007824
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00026209
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0023753
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00054773
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0075893
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012238
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0070301
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.532e-05
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00029448
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.2867e-05
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00026668
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0070391
[32m[0311 08:53:38 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.014797
[32m[0311 08:53:38 @monitor.py:393][0m cost: -0.014653
[32m[0311 08:53:38 @monitor.py:393][0m importance: 0.99996
[32m[0311 08:53:38 @monitor.py:393][0m max_score: 18
[32m[0311 08:53:38 @monitor.py:393][0m mean_score: 10.531
[32m[0311 08:53:38 @monitor.py:393][0m policy_loss: -0.47093
[32m[0311 08:53:38 @monitor.py:393][0m predict_reward_1: -0.021421
[32m[0311 08:53:38 @monitor.py:393][0m predict_reward_2: -0.021793
[32m[0311 08:53:38 @monitor.py:393][0m predict_reward_avg: -0.021607
[32m[0311 08:53:38 @monitor.py:393][0m rms_advantage_1: 0.091204
[32m[0311 08:53:38 @monitor.py:393][0m rms_advantage_2: 0.096838
[32m[0311 08:53:38 @monitor.py:393][0m rms_advantage_avg: 0.094021
[32m[0311 08:53:38 @monitor.py:393][0m value_loss: 0.68481
[32m[0311 08:53:38 @monitor.py:393][0m xentropy_loss: -208.94
[32m[0311 08:53:38 @group.py:44][0m Callbacks took 463.626 sec in total. PeriodicTrigger-Evaluator: 7 minutes 43 seconds
[32m[0311 08:53:38 @base.py:255][0m Start Epoch 19 ...
[32m[0311 09:12:40 @base.py:265][0m Epoch 19 (global_step 114000) finished, time:19 minutes 1 second.
[32m[0311 09:12:40 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-114000.
[32m[0311 09:21:21 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00059906
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0013949
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 9.6956e-05
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00074262
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00019354
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0012094
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00010122
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00060374
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00017733
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00083586
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 8.7052e-05
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00065575
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00015505
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00085913
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00026323
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026829
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0005898
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0078535
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010574
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0073813
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.535e-05
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0003024
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.3868e-05
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00027014
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0091081
[32m[0311 09:21:21 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.015427
[32m[0311 09:21:21 @monitor.py:393][0m cost: -0.013382
[32m[0311 09:21:21 @monitor.py:393][0m importance: 1.0003
[32m[0311 09:21:21 @monitor.py:393][0m max_score: 15
[32m[0311 09:21:21 @monitor.py:393][0m mean_score: 5.9375
[32m[0311 09:21:21 @monitor.py:393][0m policy_loss: -0.33101
[32m[0311 09:21:21 @monitor.py:393][0m predict_reward_1: 0.011652
[32m[0311 09:21:21 @monitor.py:393][0m predict_reward_2: 0.0093427
[32m[0311 09:21:21 @monitor.py:393][0m predict_reward_avg: 0.010497
[32m[0311 09:21:21 @monitor.py:393][0m rms_advantage_1: 0.094685
[32m[0311 09:21:21 @monitor.py:393][0m rms_advantage_2: 0.094344
[32m[0311 09:21:21 @monitor.py:393][0m rms_advantage_avg: 0.094514
[32m[0311 09:21:21 @monitor.py:393][0m value_loss: 0.6637
[32m[0311 09:21:21 @monitor.py:393][0m xentropy_loss: -204.56
[32m[0311 09:21:21 @group.py:44][0m Callbacks took 521.190 sec in total. PeriodicTrigger-Evaluator: 8 minutes 40 seconds
[32m[0311 09:21:21 @base.py:255][0m Start Epoch 20 ...
[32m[0311 09:40:22 @base.py:265][0m Epoch 20 (global_step 120000) finished, time:19 minutes 1 second.
[32m[0311 09:40:22 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-120000.
[32m[0311 09:40:22 @param.py:149][0m [HyperParamSetter] At global_step=120000, learning_rate will change to 0.00030000
[32m[0311 09:48:32 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00050968
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0011868
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00010236
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00080159
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014245
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.001051
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00011121
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00063475
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00014675
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00075293
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.1845e-05
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00076999
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013102
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00076124
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00025347
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.002665
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00058811
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0082684
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.00095374
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0088733
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.6961e-05
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033012
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.2306e-05
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00025624
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0074872
[32m[0311 09:48:32 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.01596
[32m[0311 09:48:32 @monitor.py:393][0m cost: -0.011222
[32m[0311 09:48:32 @monitor.py:393][0m importance: 0.99962
[32m[0311 09:48:32 @monitor.py:393][0m max_score: 13
[32m[0311 09:48:32 @monitor.py:393][0m mean_score: 6.0938
[32m[0311 09:48:32 @monitor.py:393][0m policy_loss: -0.056567
[32m[0311 09:48:32 @monitor.py:393][0m predict_reward_1: -0.0028737
[32m[0311 09:48:32 @monitor.py:393][0m predict_reward_2: -0.0054098
[32m[0311 09:48:32 @monitor.py:393][0m predict_reward_avg: -0.0041418
[32m[0311 09:48:32 @monitor.py:393][0m rms_advantage_1: 0.09671
[32m[0311 09:48:32 @monitor.py:393][0m rms_advantage_2: 0.099723
[32m[0311 09:48:32 @monitor.py:393][0m rms_advantage_avg: 0.098216
[32m[0311 09:48:32 @monitor.py:393][0m value_loss: 0.71832
[32m[0311 09:48:32 @monitor.py:393][0m xentropy_loss: -209.82
[32m[0311 09:48:32 @group.py:44][0m Callbacks took 490.154 sec in total. PeriodicTrigger-Evaluator: 8 minutes 9 seconds
[32m[0311 09:48:32 @base.py:255][0m Start Epoch 21 ...
[32m[0311 10:07:32 @base.py:265][0m Epoch 21 (global_step 126000) finished, time:18 minutes 59 seconds.
[32m[0311 10:07:32 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-126000.
[32m[0311 10:15:11 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00043203
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00087197
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011321
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00073318
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00016424
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010085
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00011938
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00062682
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00015995
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00073695
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.9973e-05
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00067676
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013582
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00074807
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00025739
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027813
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00056746
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0074266
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0011442
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0081456
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.7925e-05
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0003136
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.29e-05
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00025574
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.011589
[32m[0311 10:15:11 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.019174
[32m[0311 10:15:11 @monitor.py:393][0m cost: -0.014482
[32m[0311 10:15:11 @monitor.py:393][0m importance: 1
[32m[0311 10:15:11 @monitor.py:393][0m max_score: 17
[32m[0311 10:15:11 @monitor.py:393][0m mean_score: 9.3125
[32m[0311 10:15:11 @monitor.py:393][0m policy_loss: -0.53906
[32m[0311 10:15:11 @monitor.py:393][0m predict_reward_1: 0.076272
[32m[0311 10:15:11 @monitor.py:393][0m predict_reward_2: 0.077799
[32m[0311 10:15:11 @monitor.py:393][0m predict_reward_avg: 0.077036
[32m[0311 10:15:11 @monitor.py:393][0m rms_advantage_1: 0.099467
[32m[0311 10:15:11 @monitor.py:393][0m rms_advantage_2: 0.099167
[32m[0311 10:15:11 @monitor.py:393][0m rms_advantage_avg: 0.099317
[32m[0311 10:15:11 @monitor.py:393][0m value_loss: 0.79111
[32m[0311 10:15:11 @monitor.py:393][0m xentropy_loss: -210.57
[32m[0311 10:15:11 @group.py:44][0m Callbacks took 459.544 sec in total. PeriodicTrigger-Evaluator: 7 minutes 39 seconds
[32m[0311 10:15:11 @base.py:255][0m Start Epoch 22 ...
[32m[0311 10:34:09 @base.py:265][0m Epoch 22 (global_step 132000) finished, time:18 minutes 57 seconds.
[32m[0311 10:34:09 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-132000.
[32m[0311 10:41:08 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00053496
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0011515
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011999
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00089747
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014948
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010608
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013087
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00068537
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016049
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00077876
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010613
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00075758
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00014867
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0008141
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00033751
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0031008
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00067072
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0085049
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0014399
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.010334
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.7927e-05
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0003308
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.4736e-05
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00028772
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0097628
[32m[0311 10:41:08 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.016605
[32m[0311 10:41:08 @monitor.py:393][0m cost: -0.010642
[32m[0311 10:41:08 @monitor.py:393][0m importance: 1
[32m[0311 10:41:08 @monitor.py:393][0m max_score: 19
[32m[0311 10:41:08 @monitor.py:393][0m mean_score: 14.344
[32m[0311 10:41:08 @monitor.py:393][0m policy_loss: -0.11459
[32m[0311 10:41:08 @monitor.py:393][0m predict_reward_1: 0.066832
[32m[0311 10:41:08 @monitor.py:393][0m predict_reward_2: 0.068971
[32m[0311 10:41:08 @monitor.py:393][0m predict_reward_avg: 0.067901
[32m[0311 10:41:08 @monitor.py:393][0m rms_advantage_1: 0.096961
[32m[0311 10:41:08 @monitor.py:393][0m rms_advantage_2: 0.10392
[32m[0311 10:41:08 @monitor.py:393][0m rms_advantage_avg: 0.10044
[32m[0311 10:41:08 @monitor.py:393][0m value_loss: 0.83254
[32m[0311 10:41:08 @monitor.py:393][0m xentropy_loss: -208.01
[32m[0311 10:41:08 @group.py:44][0m Callbacks took 419.433 sec in total. PeriodicTrigger-Evaluator: 6 minutes 59 seconds
[32m[0311 10:41:08 @base.py:255][0m Start Epoch 23 ...
[32m[0311 11:00:07 @base.py:265][0m Epoch 23 (global_step 138000) finished, time:18 minutes 59 seconds.
[32m[0311 11:00:08 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-138000.
[32m[0311 11:08:15 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00039684
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00076082
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00012692
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00086715
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00015036
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00097127
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012903
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00069117
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.0001451
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00068237
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011176
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00073923
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013247
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00065402
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00028396
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026959
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00071773
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0079512
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010824
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0068223
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.9238e-05
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00030682
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.3243e-05
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00024968
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.011343
[32m[0311 11:08:15 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.015504
[32m[0311 11:08:15 @monitor.py:393][0m cost: -0.0091119
[32m[0311 11:08:15 @monitor.py:393][0m importance: 1
[32m[0311 11:08:15 @monitor.py:393][0m max_score: 17
[32m[0311 11:08:15 @monitor.py:393][0m mean_score: 11.625
[32m[0311 11:08:15 @monitor.py:393][0m policy_loss: 0.2035
[32m[0311 11:08:15 @monitor.py:393][0m predict_reward_1: 0.092238
[32m[0311 11:08:15 @monitor.py:393][0m predict_reward_2: 0.091968
[32m[0311 11:08:15 @monitor.py:393][0m predict_reward_avg: 0.092103
[32m[0311 11:08:15 @monitor.py:393][0m rms_advantage_1: 0.096582
[32m[0311 11:08:15 @monitor.py:393][0m rms_advantage_2: 0.09834
[32m[0311 11:08:15 @monitor.py:393][0m rms_advantage_avg: 0.097461
[32m[0311 11:08:15 @monitor.py:393][0m value_loss: 0.69341
[32m[0311 11:08:15 @monitor.py:393][0m xentropy_loss: -206.32
[32m[0311 11:08:15 @group.py:44][0m Callbacks took 488.192 sec in total. PeriodicTrigger-Evaluator: 8 minutes 7 seconds
[32m[0311 11:08:15 @base.py:255][0m Start Epoch 24 ...
[32m[0311 11:27:16 @base.py:265][0m Epoch 24 (global_step 144000) finished, time:19 minutes.
[32m[0311 11:27:16 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-144000.
[32m[0311 11:34:13 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00040638
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0006557
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011807
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00070947
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014908
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00085561
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00011183
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00059378
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00013552
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00072648
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.3753e-05
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00068853
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00012475
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00069461
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.0002537
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0024825
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00054393
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0065636
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010572
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0071508
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.6903e-05
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00028356
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.2456e-05
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00024053
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0085285
[32m[0311 11:34:13 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.02141
[32m[0311 11:34:13 @monitor.py:393][0m cost: -0.010426
[32m[0311 11:34:13 @monitor.py:393][0m importance: 0.99994
[32m[0311 11:34:13 @monitor.py:393][0m max_score: 18
[32m[0311 11:34:13 @monitor.py:393][0m mean_score: 13.938
[32m[0311 11:34:13 @monitor.py:393][0m policy_loss: 0.15275
[32m[0311 11:34:13 @monitor.py:393][0m predict_reward_1: 0.10467
[32m[0311 11:34:13 @monitor.py:393][0m predict_reward_2: 0.10545
[32m[0311 11:34:13 @monitor.py:393][0m predict_reward_avg: 0.10506
[32m[0311 11:34:13 @monitor.py:393][0m rms_advantage_1: 0.090294
[32m[0311 11:34:13 @monitor.py:393][0m rms_advantage_2: 0.091736
[32m[0311 11:34:13 @monitor.py:393][0m rms_advantage_avg: 0.091015
[32m[0311 11:34:13 @monitor.py:393][0m value_loss: 0.61792
[32m[0311 11:34:13 @monitor.py:393][0m xentropy_loss: -210.52
[32m[0311 11:34:13 @group.py:44][0m Callbacks took 417.123 sec in total. PeriodicTrigger-Evaluator: 6 minutes 56 seconds
[32m[0311 11:34:13 @base.py:255][0m Start Epoch 25 ...
[32m[0311 11:53:12 @base.py:265][0m Epoch 25 (global_step 150000) finished, time:18 minutes 59 seconds.
[32m[0311 11:53:12 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-150000.
[32m[0311 12:00:56 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00061352
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0011348
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00015244
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0010442
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00020098
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0013869
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00016621
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00076928
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00020235
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.001005
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.0001341
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00087484
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00018466
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0010704
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00038077
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0030069
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00090559
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0078724
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013439
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.00909
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.3014e-05
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00035023
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.9498e-05
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00030565
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0099189
[32m[0311 12:00:56 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.028745
[32m[0311 12:00:56 @monitor.py:393][0m cost: -0.018929
[32m[0311 12:00:56 @monitor.py:393][0m importance: 1
[32m[0311 12:00:56 @monitor.py:393][0m max_score: 18
[32m[0311 12:00:56 @monitor.py:393][0m mean_score: 12.5
[32m[0311 12:00:56 @monitor.py:393][0m policy_loss: -1.1961
[32m[0311 12:00:56 @monitor.py:393][0m predict_reward_1: 0.098855
[32m[0311 12:00:56 @monitor.py:393][0m predict_reward_2: 0.10119
[32m[0311 12:00:56 @monitor.py:393][0m predict_reward_avg: 0.10002
[32m[0311 12:00:56 @monitor.py:393][0m rms_advantage_1: 0.10402
[32m[0311 12:00:56 @monitor.py:393][0m rms_advantage_2: 0.10645
[32m[0311 12:00:56 @monitor.py:393][0m rms_advantage_avg: 0.10524
[32m[0311 12:00:56 @monitor.py:393][0m value_loss: 0.85228
[32m[0311 12:00:56 @monitor.py:393][0m xentropy_loss: -207.91
[32m[0311 12:00:56 @group.py:44][0m Callbacks took 463.605 sec in total. PeriodicTrigger-Evaluator: 7 minutes 43 seconds
[32m[0311 12:00:56 @base.py:255][0m Start Epoch 26 ...
[32m[0311 12:19:55 @base.py:265][0m Epoch 26 (global_step 156000) finished, time:18 minutes 58 seconds.
[32m[0311 12:19:55 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-156000.
[32m[0311 12:27:13 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00044554
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00084171
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 9.8033e-05
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00063783
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014171
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00086935
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.0001014
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00053576
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00013551
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00065781
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 8.675e-05
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00055596
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00011947
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00061675
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.0002676
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0022676
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00068191
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.007957
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.001126
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0057867
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.5585e-05
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.0002663
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.119e-05
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00021887
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0097526
[32m[0311 12:27:13 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.017216
[32m[0311 12:27:13 @monitor.py:393][0m cost: -0.015783
[32m[0311 12:27:13 @monitor.py:393][0m importance: 1
[32m[0311 12:27:13 @monitor.py:393][0m max_score: 18
[32m[0311 12:27:13 @monitor.py:393][0m mean_score: 11.719
[32m[0311 12:27:13 @monitor.py:393][0m policy_loss: -0.55916
[32m[0311 12:27:13 @monitor.py:393][0m predict_reward_1: 0.072001
[32m[0311 12:27:13 @monitor.py:393][0m predict_reward_2: 0.075098
[32m[0311 12:27:13 @monitor.py:393][0m predict_reward_avg: 0.073549
[32m[0311 12:27:13 @monitor.py:393][0m rms_advantage_1: 0.088468
[32m[0311 12:27:13 @monitor.py:393][0m rms_advantage_2: 0.088762
[32m[0311 12:27:13 @monitor.py:393][0m rms_advantage_avg: 0.088615
[32m[0311 12:27:13 @monitor.py:393][0m value_loss: 0.61795
[32m[0311 12:27:13 @monitor.py:393][0m xentropy_loss: -207.9
[32m[0311 12:27:13 @group.py:44][0m Callbacks took 438.697 sec in total. PeriodicTrigger-Evaluator: 7 minutes 18 seconds
[32m[0311 12:27:13 @base.py:255][0m Start Epoch 27 ...
[32m[0311 12:46:13 @base.py:265][0m Epoch 27 (global_step 162000) finished, time:18 minutes 59 seconds.
[32m[0311 12:46:13 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-162000.
[32m[0311 12:53:01 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00062921
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0010858
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00012581
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00074245
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00024128
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0012894
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013171
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00064453
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.0002171
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00093609
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011739
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00073713
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00019336
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00083841
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00035122
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.002571
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00069796
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0077791
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0015436
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0093917
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.065e-05
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00031538
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 3.0958e-05
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00028812
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0091944
[32m[0311 12:53:01 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.022098
[32m[0311 12:53:01 @monitor.py:393][0m cost: -0.0078429
[32m[0311 12:53:01 @monitor.py:393][0m importance: 1
[32m[0311 12:53:01 @monitor.py:393][0m max_score: 16
[32m[0311 12:53:01 @monitor.py:393][0m mean_score: 11.875
[32m[0311 12:53:01 @monitor.py:393][0m policy_loss: 0.27269
[32m[0311 12:53:01 @monitor.py:393][0m predict_reward_1: 0.095809
[32m[0311 12:53:01 @monitor.py:393][0m predict_reward_2: 0.091245
[32m[0311 12:53:01 @monitor.py:393][0m predict_reward_avg: 0.093527
[32m[0311 12:53:01 @monitor.py:393][0m rms_advantage_1: 0.09991
[32m[0311 12:53:01 @monitor.py:393][0m rms_advantage_2: 0.10368
[32m[0311 12:53:01 @monitor.py:393][0m rms_advantage_avg: 0.10179
[32m[0311 12:53:01 @monitor.py:393][0m value_loss: 0.80287
[32m[0311 12:53:01 @monitor.py:393][0m xentropy_loss: -207.95
[32m[0311 12:53:01 @group.py:44][0m Callbacks took 407.465 sec in total. PeriodicTrigger-Evaluator: 6 minutes 47 seconds
[32m[0311 12:53:01 @base.py:255][0m Start Epoch 28 ...
[32m[0311 13:12:02 @base.py:265][0m Epoch 28 (global_step 168000) finished, time:19 minutes 1 second.
[32m[0311 13:12:02 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-168000.
[32m[0311 13:17:22 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00047208
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00088756
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00016211
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00093515
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00022145
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0012438
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00015688
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0008323
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00019754
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00090242
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00013748
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00090083
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00018747
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00099684
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00036475
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0031551
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0007652
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.006981
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012203
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0074224
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.3258e-05
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00034679
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 3.182e-05
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00032042
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.011393
[32m[0311 13:17:22 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.023706
[32m[0311 13:17:22 @monitor.py:393][0m cost: -0.012032
[32m[0311 13:17:22 @monitor.py:393][0m importance: 1
[32m[0311 13:17:22 @monitor.py:393][0m max_score: 18
[32m[0311 13:17:22 @monitor.py:393][0m mean_score: 12.562
[32m[0311 13:17:22 @monitor.py:393][0m policy_loss: -0.24446
[32m[0311 13:17:22 @monitor.py:393][0m predict_reward_1: 0.15815
[32m[0311 13:17:22 @monitor.py:393][0m predict_reward_2: 0.1597
[32m[0311 13:17:22 @monitor.py:393][0m predict_reward_avg: 0.15892
[32m[0311 13:17:22 @monitor.py:393][0m rms_advantage_1: 0.099382
[32m[0311 13:17:22 @monitor.py:393][0m rms_advantage_2: 0.10439
[32m[0311 13:17:22 @monitor.py:393][0m rms_advantage_avg: 0.10189
[32m[0311 13:17:22 @monitor.py:393][0m value_loss: 0.79323
[32m[0311 13:17:22 @monitor.py:393][0m xentropy_loss: -208.89
[32m[0311 13:17:22 @group.py:44][0m Callbacks took 319.778 sec in total. PeriodicTrigger-Evaluator: 5 minutes 19 seconds
[32m[0311 13:17:22 @base.py:255][0m Start Epoch 29 ...
[32m[0311 13:36:22 @base.py:265][0m Epoch 29 (global_step 174000) finished, time:18 minutes 59 seconds.
[32m[0311 13:36:22 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-174000.
[32m[0311 13:42:49 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00043541
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0008855
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011643
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00075537
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00012633
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0007611
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.0001218
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00070977
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00012732
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00062121
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010447
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00068956
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00011514
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00069626
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030759
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026806
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.000828
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.008537
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0010543
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0062441
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.9524e-05
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033117
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.2449e-05
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00023311
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.010264
[32m[0311 13:42:49 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.024481
[32m[0311 13:42:49 @monitor.py:393][0m cost: -0.011797
[32m[0311 13:42:49 @monitor.py:393][0m importance: 1
[32m[0311 13:42:49 @monitor.py:393][0m max_score: 18
[32m[0311 13:42:49 @monitor.py:393][0m mean_score: 13.531
[32m[0311 13:42:49 @monitor.py:393][0m policy_loss: -0.13613
[32m[0311 13:42:49 @monitor.py:393][0m predict_reward_1: 0.10872
[32m[0311 13:42:49 @monitor.py:393][0m predict_reward_2: 0.10657
[32m[0311 13:42:49 @monitor.py:393][0m predict_reward_avg: 0.10764
[32m[0311 13:42:49 @monitor.py:393][0m rms_advantage_1: 0.096102
[32m[0311 13:42:49 @monitor.py:393][0m rms_advantage_2: 0.094828
[32m[0311 13:42:49 @monitor.py:393][0m rms_advantage_avg: 0.095465
[32m[0311 13:42:49 @monitor.py:393][0m value_loss: 0.73573
[32m[0311 13:42:49 @monitor.py:393][0m xentropy_loss: -210.96
[32m[0311 13:42:49 @group.py:44][0m Callbacks took 387.430 sec in total. PeriodicTrigger-Evaluator: 6 minutes 27 seconds
[32m[0311 13:42:49 @base.py:255][0m Start Epoch 30 ...
[32m[0311 14:01:49 @base.py:265][0m Epoch 30 (global_step 180000) finished, time:18 minutes 59 seconds.
[32m[0311 14:01:49 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-180000.
[32m[0311 14:08:05 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00040815
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00075078
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00010817
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00068898
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00015503
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010117
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00011439
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00059157
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00015104
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00068411
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 9.5926e-05
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00065561
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013404
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0007195
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00029345
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0023846
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0006359
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0075382
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0014323
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0079488
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.8179e-05
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00027975
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.5416e-05
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00025994
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0085831
[32m[0311 14:08:05 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.020386
[32m[0311 14:08:05 @monitor.py:393][0m cost: -0.0075056
[32m[0311 14:08:05 @monitor.py:393][0m importance: 1.0001
[32m[0311 14:08:05 @monitor.py:393][0m max_score: 19
[32m[0311 14:08:05 @monitor.py:393][0m mean_score: 12.75
[32m[0311 14:08:05 @monitor.py:393][0m policy_loss: 0.47975
[32m[0311 14:08:05 @monitor.py:393][0m predict_reward_1: 0.084556
[32m[0311 14:08:05 @monitor.py:393][0m predict_reward_2: 0.087385
[32m[0311 14:08:05 @monitor.py:393][0m predict_reward_avg: 0.08597
[32m[0311 14:08:05 @monitor.py:393][0m rms_advantage_1: 0.093849
[32m[0311 14:08:05 @monitor.py:393][0m rms_advantage_2: 0.099111
[32m[0311 14:08:05 @monitor.py:393][0m rms_advantage_avg: 0.09648
[32m[0311 14:08:05 @monitor.py:393][0m value_loss: 0.66145
[32m[0311 14:08:05 @monitor.py:393][0m xentropy_loss: -210.19
[32m[0311 14:08:05 @group.py:44][0m Callbacks took 376.721 sec in total. PeriodicTrigger-Evaluator: 6 minutes 16 seconds
[32m[0311 14:08:05 @base.py:255][0m Start Epoch 31 ...
[32m[0311 14:27:08 @base.py:265][0m Epoch 31 (global_step 186000) finished, time:19 minutes 2 seconds.
[32m[0311 14:27:08 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-186000.
[32m[0311 14:33:51 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00045241
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00097848
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00010643
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00081891
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00011775
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00089437
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012538
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00062085
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00013529
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00063861
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010646
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00063795
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00012813
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00067711
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030083
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.002605
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00065892
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0065987
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0011559
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0066149
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.9217e-05
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00028725
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.3827e-05
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00024501
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0098512
[32m[0311 14:33:51 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.023007
[32m[0311 14:33:51 @monitor.py:393][0m cost: -0.0071019
[32m[0311 14:33:51 @monitor.py:393][0m importance: 1
[32m[0311 14:33:51 @monitor.py:393][0m max_score: 17
[32m[0311 14:33:51 @monitor.py:393][0m mean_score: 13.094
[32m[0311 14:33:51 @monitor.py:393][0m policy_loss: 0.60557
[32m[0311 14:33:51 @monitor.py:393][0m predict_reward_1: 0.15
[32m[0311 14:33:51 @monitor.py:393][0m predict_reward_2: 0.1469
[32m[0311 14:33:51 @monitor.py:393][0m predict_reward_avg: 0.14845
[32m[0311 14:33:51 @monitor.py:393][0m rms_advantage_1: 0.089211
[32m[0311 14:33:51 @monitor.py:393][0m rms_advantage_2: 0.094951
[32m[0311 14:33:51 @monitor.py:393][0m rms_advantage_avg: 0.092081
[32m[0311 14:33:51 @monitor.py:393][0m value_loss: 0.59514
[32m[0311 14:33:51 @monitor.py:393][0m xentropy_loss: -210.98
[32m[0311 14:33:51 @group.py:44][0m Callbacks took 403.525 sec in total. PeriodicTrigger-Evaluator: 6 minutes 43 seconds
[32m[0311 14:33:51 @base.py:255][0m Start Epoch 32 ...
[32m[0311 14:52:53 @base.py:265][0m Epoch 32 (global_step 192000) finished, time:19 minutes 1 second.
[32m[0311 14:52:53 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-192000.
[32m[0311 15:00:29 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00044395
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00091152
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00012069
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00078756
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00017332
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010771
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012826
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.0006638
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00017009
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00082005
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010761
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00069043
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00015393
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0007352
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00031473
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026082
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00078538
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0063412
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.00143
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0078116
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 1.9582e-05
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00029861
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.6551e-05
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00025786
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.010784
[32m[0311 15:00:29 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.015987
[32m[0311 15:00:29 @monitor.py:393][0m cost: -0.013498
[32m[0311 15:00:29 @monitor.py:393][0m importance: 0.99998
[32m[0311 15:00:29 @monitor.py:393][0m max_score: 17
[32m[0311 15:00:29 @monitor.py:393][0m mean_score: 12.719
[32m[0311 15:00:29 @monitor.py:393][0m policy_loss: -0.46215
[32m[0311 15:00:29 @monitor.py:393][0m predict_reward_1: 0.082509
[32m[0311 15:00:29 @monitor.py:393][0m predict_reward_2: 0.083565
[32m[0311 15:00:29 @monitor.py:393][0m predict_reward_avg: 0.083037
[32m[0311 15:00:29 @monitor.py:393][0m rms_advantage_1: 0.096853
[32m[0311 15:00:29 @monitor.py:393][0m rms_advantage_2: 0.10098
[32m[0311 15:00:29 @monitor.py:393][0m rms_advantage_avg: 0.098916
[32m[0311 15:00:29 @monitor.py:393][0m value_loss: 0.77188
[32m[0311 15:00:29 @monitor.py:393][0m xentropy_loss: -203.75
[32m[0311 15:00:29 @group.py:44][0m Callbacks took 456.060 sec in total. PeriodicTrigger-Evaluator: 7 minutes 35 seconds
[32m[0311 15:00:29 @base.py:255][0m Start Epoch 33 ...
[32m[0311 15:19:29 @base.py:265][0m Epoch 33 (global_step 198000) finished, time:19 minutes.
[32m[0311 15:19:30 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-198000.
[32m[0311 15:25:08 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00048013
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0010283
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00013558
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00095169
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00017141
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0011485
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014675
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00072348
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00018803
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00092184
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00012054
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00070355
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00017109
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00081028
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00033874
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0024737
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00073871
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0079841
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.001065
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0077151
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1027e-05
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00032672
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.75e-05
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00027625
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.011568
[32m[0311 15:25:08 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.024068
[32m[0311 15:25:08 @monitor.py:393][0m cost: -0.011459
[32m[0311 15:25:08 @monitor.py:393][0m importance: 0.99998
[32m[0311 15:25:08 @monitor.py:393][0m max_score: 20
[32m[0311 15:25:08 @monitor.py:393][0m mean_score: 13.625
[32m[0311 15:25:08 @monitor.py:393][0m policy_loss: -0.18531
[32m[0311 15:25:08 @monitor.py:393][0m predict_reward_1: 0.14653
[32m[0311 15:25:08 @monitor.py:393][0m predict_reward_2: 0.14701
[32m[0311 15:25:08 @monitor.py:393][0m predict_reward_avg: 0.14677
[32m[0311 15:25:08 @monitor.py:393][0m rms_advantage_1: 0.10178
[32m[0311 15:25:08 @monitor.py:393][0m rms_advantage_2: 0.10229
[32m[0311 15:25:08 @monitor.py:393][0m rms_advantage_avg: 0.10204
[32m[0311 15:25:08 @monitor.py:393][0m value_loss: 0.82307
[32m[0311 15:25:08 @monitor.py:393][0m xentropy_loss: -210.45
[32m[0311 15:25:08 @group.py:44][0m Callbacks took 338.185 sec in total. PeriodicTrigger-Evaluator: 5 minutes 37 seconds
[32m[0311 15:25:08 @base.py:255][0m Start Epoch 34 ...
[32m[0311 15:44:07 @base.py:265][0m Epoch 34 (global_step 204000) finished, time:18 minutes 59 seconds.
[32m[0311 15:44:07 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-204000.
[32m[0311 15:50:43 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00042963
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00076042
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.0001289
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0007894
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00017085
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010134
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012829
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00066348
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016889
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.0008998
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010917
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.000665
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.0001542
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.0007585
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00031374
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026751
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00075987
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0085193
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.001101
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0068427
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0526e-05
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00029848
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7024e-05
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00023929
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0092709
[32m[0311 15:50:43 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.027977
[32m[0311 15:50:43 @monitor.py:393][0m cost: -0.013779
[32m[0311 15:50:43 @monitor.py:393][0m importance: 1
[32m[0311 15:50:43 @monitor.py:393][0m max_score: 19
[32m[0311 15:50:43 @monitor.py:393][0m mean_score: 13.844
[32m[0311 15:50:43 @monitor.py:393][0m policy_loss: -0.32863
[32m[0311 15:50:43 @monitor.py:393][0m predict_reward_1: 0.095526
[32m[0311 15:50:43 @monitor.py:393][0m predict_reward_2: 0.09696
[32m[0311 15:50:43 @monitor.py:393][0m predict_reward_avg: 0.096243
[32m[0311 15:50:43 @monitor.py:393][0m rms_advantage_1: 0.091746
[32m[0311 15:50:43 @monitor.py:393][0m rms_advantage_2: 0.092281
[32m[0311 15:50:43 @monitor.py:393][0m rms_advantage_avg: 0.092013
[32m[0311 15:50:43 @monitor.py:393][0m value_loss: 0.63451
[32m[0311 15:50:43 @monitor.py:393][0m xentropy_loss: -206.96
[32m[0311 15:50:43 @group.py:44][0m Callbacks took 395.333 sec in total. PeriodicTrigger-Evaluator: 6 minutes 35 seconds
[32m[0311 15:50:43 @base.py:255][0m Start Epoch 35 ...
[32m[0311 16:09:44 @base.py:265][0m Epoch 35 (global_step 210000) finished, time:19 minutes 1 second.
[32m[0311 16:09:44 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-210000.
[32m[0311 16:16:05 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00052856
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0011195
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00013344
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0009108
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00020578
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0014004
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014114
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00070834
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.000209
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00088354
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.0001167
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00072085
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00018501
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00092357
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030921
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026062
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00069733
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0067206
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013031
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0083672
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1096e-05
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033521
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.8801e-05
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00028527
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.010681
[32m[0311 16:16:05 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.025213
[32m[0311 16:16:05 @monitor.py:393][0m cost: -0.0097314
[32m[0311 16:16:05 @monitor.py:393][0m importance: 0.99993
[32m[0311 16:16:05 @monitor.py:393][0m max_score: 19
[32m[0311 16:16:05 @monitor.py:393][0m mean_score: 12.906
[32m[0311 16:16:05 @monitor.py:393][0m policy_loss: 0.12523
[32m[0311 16:16:05 @monitor.py:393][0m predict_reward_1: 0.15161
[32m[0311 16:16:05 @monitor.py:393][0m predict_reward_2: 0.1494
[32m[0311 16:16:05 @monitor.py:393][0m predict_reward_avg: 0.15051
[32m[0311 16:16:05 @monitor.py:393][0m rms_advantage_1: 0.095083
[32m[0311 16:16:05 @monitor.py:393][0m rms_advantage_2: 0.10075
[32m[0311 16:16:05 @monitor.py:393][0m rms_advantage_avg: 0.097918
[32m[0311 16:16:05 @monitor.py:393][0m value_loss: 0.71251
[32m[0311 16:16:05 @monitor.py:393][0m xentropy_loss: -208.34
[32m[0311 16:16:05 @group.py:44][0m Callbacks took 380.854 sec in total. PeriodicTrigger-Evaluator: 6 minutes 20 seconds
[32m[0311 16:16:05 @base.py:255][0m Start Epoch 36 ...
[32m[0311 16:35:04 @base.py:265][0m Epoch 36 (global_step 216000) finished, time:18 minutes 59 seconds.
[32m[0311 16:35:05 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-216000.
[32m[0311 16:40:40 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00043865
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00085265
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.0001097
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00073892
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00015333
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010026
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012137
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00060433
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016283
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00081494
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010163
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.0006657
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00014417
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00087254
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00033597
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027049
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00076915
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0082733
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0014065
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0087998
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0155e-05
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00031531
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7007e-05
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00025598
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.0086822
[32m[0311 16:40:40 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.025369
[32m[0311 16:40:40 @monitor.py:393][0m cost: -0.01497
[32m[0311 16:40:40 @monitor.py:393][0m importance: 1
[32m[0311 16:40:40 @monitor.py:393][0m max_score: 18
[32m[0311 16:40:40 @monitor.py:393][0m mean_score: 13.781
[32m[0311 16:40:40 @monitor.py:393][0m policy_loss: -0.55178
[32m[0311 16:40:40 @monitor.py:393][0m predict_reward_1: 0.15584
[32m[0311 16:40:40 @monitor.py:393][0m predict_reward_2: 0.15999
[32m[0311 16:40:40 @monitor.py:393][0m predict_reward_avg: 0.15792
[32m[0311 16:40:40 @monitor.py:393][0m rms_advantage_1: 0.096847
[32m[0311 16:40:40 @monitor.py:393][0m rms_advantage_2: 0.099193
[32m[0311 16:40:40 @monitor.py:393][0m rms_advantage_avg: 0.09802
[32m[0311 16:40:40 @monitor.py:393][0m value_loss: 0.73462
[32m[0311 16:40:40 @monitor.py:393][0m xentropy_loss: -209.9
[32m[0311 16:40:40 @group.py:44][0m Callbacks took 335.264 sec in total. PeriodicTrigger-Evaluator: 5 minutes 35 seconds
[32m[0311 16:40:40 @base.py:255][0m Start Epoch 37 ...
[32m[0311 16:59:40 @base.py:265][0m Epoch 37 (global_step 222000) finished, time:19 minutes.
[32m[0311 16:59:41 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-222000.
[32m[0311 17:06:26 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00042171
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00080517
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011633
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00089213
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014545
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00096107
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013413
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00066727
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00016762
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00071765
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011231
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00067886
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00014831
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00076244
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00028937
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026088
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.0007006
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0072287
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013063
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0073527
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0772e-05
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00031329
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.7243e-05
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00024964
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.016637
[32m[0311 17:06:26 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.01586
[32m[0311 17:06:26 @monitor.py:393][0m cost: -0.01147
[32m[0311 17:06:26 @monitor.py:393][0m importance: 0.99998
[32m[0311 17:06:26 @monitor.py:393][0m max_score: 17
[32m[0311 17:06:26 @monitor.py:393][0m mean_score: 13
[32m[0311 17:06:26 @monitor.py:393][0m policy_loss: -0.057177
[32m[0311 17:06:26 @monitor.py:393][0m predict_reward_1: 0.14909
[32m[0311 17:06:26 @monitor.py:393][0m predict_reward_2: 0.15128
[32m[0311 17:06:26 @monitor.py:393][0m predict_reward_avg: 0.15018
[32m[0311 17:06:26 @monitor.py:393][0m rms_advantage_1: 0.095932
[32m[0311 17:06:26 @monitor.py:393][0m rms_advantage_2: 0.096499
[32m[0311 17:06:26 @monitor.py:393][0m rms_advantage_avg: 0.096216
[32m[0311 17:06:26 @monitor.py:393][0m value_loss: 0.66998
[32m[0311 17:06:26 @monitor.py:393][0m xentropy_loss: -208.1
[32m[0311 17:06:26 @group.py:44][0m Callbacks took 405.309 sec in total. PeriodicTrigger-Evaluator: 6 minutes 45 seconds
[32m[0311 17:06:26 @base.py:255][0m Start Epoch 38 ...
[32m[0311 17:25:26 @base.py:265][0m Epoch 38 (global_step 228000) finished, time:19 minutes.
[32m[0311 17:25:26 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-228000.
[32m[0311 17:31:39 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00047907
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00083521
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00016578
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.0010405
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00022828
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0013606
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00015777
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00080473
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00021098
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00097998
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.0001304
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00079879
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00019341
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00096733
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00037918
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0030917
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00076934
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0072179
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0015247
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0081638
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.2878e-05
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00033249
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 3.0945e-05
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00030804
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.012665
[32m[0311 17:31:39 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.022676
[32m[0311 17:31:39 @monitor.py:393][0m cost: -0.014263
[32m[0311 17:31:39 @monitor.py:393][0m importance: 1
[32m[0311 17:31:39 @monitor.py:393][0m max_score: 19
[32m[0311 17:31:39 @monitor.py:393][0m mean_score: 13.719
[32m[0311 17:31:39 @monitor.py:393][0m policy_loss: -0.69106
[32m[0311 17:31:39 @monitor.py:393][0m predict_reward_1: 0.11674
[32m[0311 17:31:39 @monitor.py:393][0m predict_reward_2: 0.11721
[32m[0311 17:31:39 @monitor.py:393][0m predict_reward_avg: 0.11698
[32m[0311 17:31:39 @monitor.py:393][0m rms_advantage_1: 0.11129
[32m[0311 17:31:39 @monitor.py:393][0m rms_advantage_2: 0.11032
[32m[0311 17:31:39 @monitor.py:393][0m rms_advantage_avg: 0.1108
[32m[0311 17:31:39 @monitor.py:393][0m value_loss: 0.94158
[32m[0311 17:31:39 @monitor.py:393][0m xentropy_loss: -207.61
[32m[0311 17:31:39 @group.py:44][0m Callbacks took 373.242 sec in total. PeriodicTrigger-Evaluator: 6 minutes 12 seconds
[32m[0311 17:31:39 @base.py:255][0m Start Epoch 39 ...
[32m[0311 17:50:39 @base.py:265][0m Epoch 39 (global_step 234000) finished, time:19 minutes.
[32m[0311 17:50:40 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-234000.
[32m[0311 17:57:10 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.0005961
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.0010949
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00014187
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00078428
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00024893
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0012695
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013478
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00067682
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00022572
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00091383
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010976
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00066415
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00018962
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00090306
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00032996
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0029452
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00072812
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0072919
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012107
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0084901
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0781e-05
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00032558
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.8514e-05
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00028308
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.012303
[32m[0311 17:57:10 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.023601
[32m[0311 17:57:10 @monitor.py:393][0m cost: -0.0077822
[32m[0311 17:57:10 @monitor.py:393][0m importance: 1
[32m[0311 17:57:10 @monitor.py:393][0m max_score: 18
[32m[0311 17:57:10 @monitor.py:393][0m mean_score: 12.469
[32m[0311 17:57:10 @monitor.py:393][0m policy_loss: 0.30904
[32m[0311 17:57:10 @monitor.py:393][0m predict_reward_1: 0.11545
[32m[0311 17:57:10 @monitor.py:393][0m predict_reward_2: 0.11695
[32m[0311 17:57:10 @monitor.py:393][0m predict_reward_avg: 0.1162
[32m[0311 17:57:10 @monitor.py:393][0m rms_advantage_1: 0.10032
[32m[0311 17:57:10 @monitor.py:393][0m rms_advantage_2: 0.10619
[32m[0311 17:57:10 @monitor.py:393][0m rms_advantage_avg: 0.10326
[32m[0311 17:57:10 @monitor.py:393][0m value_loss: 0.78341
[32m[0311 17:57:10 @monitor.py:393][0m xentropy_loss: -208.86
[32m[0311 17:57:10 @group.py:44][0m Callbacks took 390.291 sec in total. PeriodicTrigger-Evaluator: 6 minutes 30 seconds
[32m[0311 17:57:10 @base.py:255][0m Start Epoch 40 ...
[32m[0311 18:16:10 @base.py:265][0m Epoch 40 (global_step 240000) finished, time:19 minutes.
[32m[0311 18:16:10 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-240000.
[32m[0311 18:21:58 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00040311
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00081398
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.0001212
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00081828
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00017068
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010737
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013382
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00068262
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00017478
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00080544
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010897
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00066567
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00014299
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00074375
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030172
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027456
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00058286
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0080262
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0011045
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0067364
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0204e-05
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00031316
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.5756e-05
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00024265
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.010448
[32m[0311 18:21:58 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.020088
[32m[0311 18:21:58 @monitor.py:393][0m cost: -0.012233
[32m[0311 18:21:58 @monitor.py:393][0m importance: 0.99996
[32m[0311 18:21:58 @monitor.py:393][0m max_score: 19
[32m[0311 18:21:58 @monitor.py:393][0m mean_score: 14.531
[32m[0311 18:21:58 @monitor.py:393][0m policy_loss: -0.089387
[32m[0311 18:21:58 @monitor.py:393][0m predict_reward_1: 0.16099
[32m[0311 18:21:58 @monitor.py:393][0m predict_reward_2: 0.15818
[32m[0311 18:21:58 @monitor.py:393][0m predict_reward_avg: 0.15959
[32m[0311 18:21:58 @monitor.py:393][0m rms_advantage_1: 0.09196
[32m[0311 18:21:58 @monitor.py:393][0m rms_advantage_2: 0.091321
[32m[0311 18:21:58 @monitor.py:393][0m rms_advantage_avg: 0.09164
[32m[0311 18:21:58 @monitor.py:393][0m value_loss: 0.63388
[32m[0311 18:21:58 @monitor.py:393][0m xentropy_loss: -211.04
[32m[0311 18:21:58 @group.py:44][0m Callbacks took 347.548 sec in total. PeriodicTrigger-Evaluator: 5 minutes 47 seconds
[32m[0311 18:21:58 @base.py:255][0m Start Epoch 41 ...
[32m[0311 18:40:58 @base.py:265][0m Epoch 41 (global_step 246000) finished, time:18 minutes 59 seconds.
[32m[0311 18:40:58 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-246000.
[32m[0311 18:46:59 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00041144
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00068915
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.0001551
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00086551
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00016845
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00093307
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00014172
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00069975
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00015813
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00068926
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011816
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00068339
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013465
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00071588
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00031376
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0026532
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00098168
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.008832
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012935
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0063973
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1685e-05
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00031757
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.4585e-05
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00023223
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.012479
[32m[0311 18:46:59 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.017377
[32m[0311 18:46:59 @monitor.py:393][0m cost: -0.0096737
[32m[0311 18:46:59 @monitor.py:393][0m importance: 1
[32m[0311 18:46:59 @monitor.py:393][0m max_score: 18
[32m[0311 18:46:59 @monitor.py:393][0m mean_score: 14.406
[32m[0311 18:46:59 @monitor.py:393][0m policy_loss: 0.067949
[32m[0311 18:46:59 @monitor.py:393][0m predict_reward_1: 0.13117
[32m[0311 18:46:59 @monitor.py:393][0m predict_reward_2: 0.13369
[32m[0311 18:46:59 @monitor.py:393][0m predict_reward_avg: 0.13243
[32m[0311 18:46:59 @monitor.py:393][0m rms_advantage_1: 0.099136
[32m[0311 18:46:59 @monitor.py:393][0m rms_advantage_2: 0.10207
[32m[0311 18:46:59 @monitor.py:393][0m rms_advantage_avg: 0.1006
[32m[0311 18:46:59 @monitor.py:393][0m value_loss: 0.75382
[32m[0311 18:46:59 @monitor.py:393][0m xentropy_loss: -206
[32m[0311 18:46:59 @group.py:44][0m Callbacks took 361.913 sec in total. PeriodicTrigger-Evaluator: 6 minutes 1 second
[32m[0311 18:46:59 @base.py:255][0m Start Epoch 42 ...
[32m[0311 19:05:58 @base.py:265][0m Epoch 42 (global_step 252000) finished, time:18 minutes 58 seconds.
[32m[0311 19:05:59 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-252000.
[32m[0311 19:12:18 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00042821
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00074445
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.000135
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00073258
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.0001919
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.0010622
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00013244
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00070274
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.00017929
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00085155
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00011224
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00069472
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00016177
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00084286
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00034366
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027499
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00058404
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0058088
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0013749
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0088645
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.0325e-05
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00030098
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.9325e-05
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00027487
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.010018
[32m[0311 19:12:18 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.027079
[32m[0311 19:12:18 @monitor.py:393][0m cost: -0.013333
[32m[0311 19:12:18 @monitor.py:393][0m importance: 1
[32m[0311 19:12:18 @monitor.py:393][0m max_score: 20
[32m[0311 19:12:18 @monitor.py:393][0m mean_score: 14.438
[32m[0311 19:12:18 @monitor.py:393][0m policy_loss: -0.39955
[32m[0311 19:12:18 @monitor.py:393][0m predict_reward_1: 0.076554
[32m[0311 19:12:18 @monitor.py:393][0m predict_reward_2: 0.07562
[32m[0311 19:12:18 @monitor.py:393][0m predict_reward_avg: 0.076087
[32m[0311 19:12:18 @monitor.py:393][0m rms_advantage_1: 0.099714
[32m[0311 19:12:18 @monitor.py:393][0m rms_advantage_2: 0.10065
[32m[0311 19:12:18 @monitor.py:393][0m rms_advantage_avg: 0.10018
[32m[0311 19:12:18 @monitor.py:393][0m value_loss: 0.79166
[32m[0311 19:12:18 @monitor.py:393][0m xentropy_loss: -209.87
[32m[0311 19:12:18 @group.py:44][0m Callbacks took 379.292 sec in total. PeriodicTrigger-Evaluator: 6 minutes 19 seconds
[32m[0311 19:12:18 @base.py:255][0m Start Epoch 43 ...
[32m[0311 19:31:21 @base.py:265][0m Epoch 43 (global_step 258000) finished, time:19 minutes 2 seconds.
[32m[0311 19:31:21 @saver.py:84][0m Model saved to train_log/train-atari-Pong-v0/model-258000.
[32m[0311 19:37:00 @common.py:86][0m Waiting for all the workers to finish the last run...
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv0/W/rms: 0.00043032
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv0/b/rms: 0.00090423
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv1-1/W/rms: 0.00011018
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv1-1/b/rms: 0.00076446
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv1-2/W/rms: 0.00014238
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv1-2/b/rms: 0.00095192
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv2-1/W/rms: 0.00012707
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv2-1/b/rms: 0.00060552
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv2-2/W/rms: 0.0001554
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv2-2/b/rms: 0.00067168
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv3-1/W/rms: 0.00010863
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv3-1/b/rms: 0.00063141
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv3-2/W/rms: 0.00013761
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/conv3-2/b/rms: 0.00062821
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-pi/W/rms: 0.00030845
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-pi/b/rms: 0.0027793
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-v_1/W/rms: 0.00073963
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-v_1/b/rms: 0.0075707
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-v_2/W/rms: 0.0012728
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc-v_2/b/rms: 0.0087486
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc0-1/W/rms: 2.1292e-05
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc0-1/b/rms: 0.00030826
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc0-2/W/rms: 2.4349e-05
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/fc0-2/b/rms: 0.00023042
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/prelu-1/alpha/rms: 0.014795
[32m[0311 19:37:00 @monitor.py:393][0m SummaryGradient/prelu-2/alpha/rms: 0.023424
[32m[0311 19:37:00 @monitor.py:393][0m cost: -0.012564
[32m[0311 19:37:00 @monitor.py:393][0m importance: 1
[32m[0311 19:37:00 @monitor.py:393][0m max_score: 19
[32m[0311 19:37:00 @monitor.py:393][0m mean_score: 13.531
[32m[0311 19:37:00 @monitor.py:393][0m policy_loss: -0.20095
[32m[0311 19:37:00 @monitor.py:393][0m predict_reward_1: 0.18626
[32m[0311 19:37:00 @monitor.py:393][0m predict_reward_2: 0.18185
[32m[0311 19:37:00 @monitor.py:393][0m predict_reward_avg: 0.18406
[32m[0311 19:37:00 @monitor.py:393][0m rms_advantage_1: 0.095097
[32m[0311 19:37:00 @monitor.py:393][0m rms_advantage_2: 0.098015
[32m[0311 19:37:00 @monitor.py:393][0m rms_advantage_avg: 0.096556
[32m[0311 19:37:00 @monitor.py:393][0m value_loss: 0.71824
[32m[0311 19:37:00 @monitor.py:393][0m xentropy_loss: -212.55
[32m[0311 19:37:00 @group.py:44][0m Callbacks took 338.975 sec in total. PeriodicTrigger-Evaluator: 5 minutes 38 seconds
[32m[0311 19:37:00 @base.py:255][0m Start Epoch 44 ...
